{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Type Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Datasets ###\n",
    "red_wine = pd.read_csv('/Users/tanchaud/CAB_Berlin/Project_2/Sprint_1/winequality-red.csv', sep=';')\n",
    "white_wine =  pd.read_csv('/Users/tanchaud/CAB_Berlin/Project_2/Sprint_1/winequality-white.csv', sep= ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Data Enriching ##### ... creating new columns that will help define the targets for each model. \n",
    "\n",
    "# we are creating a new column called \"quality_label\", we define a range and associate that range with a label\n",
    "red_wine['quality_label'] = red_wine['quality'].apply(lambda value: 'low'\n",
    "if value <= 5 else 'medium'\n",
    "if value <= 7 else 'high')\n",
    "\n",
    "# here we are transforming these labels into categrical data type (specific to pandas) instead of simple string\n",
    "red_wine['quality_label'] = pd.Categorical(red_wine['quality_label'],\n",
    "categories=['low', 'medium', 'high'])\n",
    "\n",
    "red_wine['wine_type'] = 'red'\n",
    "\n",
    "# we are creating a new column called \"quality_label\", we define a range and associate that range with a label\n",
    "white_wine['quality_label'] = white_wine['quality'].apply(lambda value: 'low'\n",
    "if value <= 5 else 'medium'\n",
    "if value <= 7 else 'high')\n",
    "\n",
    "# here we are transforming these labels into categrical data type (specific to pandas) instead of simple string\n",
    "white_wine['quality_label'] = pd.Categorical(white_wine['quality_label'],\n",
    "categories=['low', 'medium', 'high'])\n",
    "\n",
    "white_wine['wine_type'] = 'white'\n",
    "\n",
    "# Data Cleaning # \n",
    "red_wine = red_wine.drop_duplicates()\n",
    "white_wine = white_wine.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(x=[white_wine.shape[0],red_wine.shape[0]], labels=['White Wine', 'Red Wine'], autopct = '%0.0f%%')\n",
    "plt.savefig('wines_count.png', facecolor='w')\n",
    "plt.title('Wines')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Structuring # \n",
    "wines = pd.concat([red_wine, white_wine])\n",
    "wines = wines.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "wines = wines.drop(['quality'],axis=1)\n",
    "\n",
    "wines.head(3)\n",
    "print(wines.shape)\n",
    "\n",
    "##### ------------------ HISTOGRAMS ---------------------- ##### \n",
    "\n",
    "features = wines.select_dtypes(include=['float64']).columns\n",
    "\n",
    "for feature in features: \n",
    "\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        fig.set_size_inches(10,7)\n",
    "\n",
    "        wines[feature].plot.hist(bins=15, color='blue', edgecolor='black', linewidth=1.0)\n",
    "        plt.xlabel(feature)\n",
    "\n",
    "        plt.show() \n",
    "        \n",
    "\n",
    "#### ----------------- BOXPLOTS ----------------------- #####\n",
    "\n",
    "features = wines.select_dtypes(include=['float64']).columns\n",
    "\n",
    "for feature in features: \n",
    "\n",
    "        fig = plt.figure()\n",
    "\n",
    "        # Seaborn Aesthetics Settings \n",
    "        sns.set_theme()\n",
    "        sns.set_context()\n",
    "        \n",
    "        fig.set_size_inches(10,7)\n",
    "        sns.set(font_scale = 1.5)\n",
    "        sns.boxplot(x=wines['wine_type'],y=wines[feature])\n",
    "        \n",
    "        plt.show()   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations from Univariate Analysis: \n",
    "\n",
    "#### Wine Type: \n",
    "#### Difference between red and white wine for each feature. Outliers are present. The data is positively skewed and highly imbalanced. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier Removal #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = red_wine; feature = 'alcohol'\n",
    "\n",
    "df_no_outliers = df.copy(deep=True)\n",
    "\n",
    "# Figure Settings \n",
    "sns.set_theme()\n",
    "sns.set_context()\n",
    "fig.set_size_inches(10,7)\n",
    "sns.set(font_scale = 1.5)\n",
    "# Plot Feature \n",
    "sns.boxplot(x=df_no_outliers['quality_label'],y=df_no_outliers[feature])\n",
    "plt.title('Before Outlier Removal')\n",
    "plt.show() \n",
    "# Check Count \n",
    "print('Before Outlier Removal')\n",
    "print(df_no_outliers[df_no_outliers['quality_label']=='medium']['alcohol'].describe().loc['count'])         \n",
    "\n",
    "\n",
    "# Outlier Removal\n",
    "q1=df_no_outliers[feature].quantile(0.25)\n",
    "q3=df_no_outliers[feature].quantile(0.75)\n",
    "iqr=(q3-q1)\n",
    "lower=(q1-(1.5*iqr))\n",
    "upper=(q3+(1.5*iqr))\n",
    "median=df_no_outliers[feature].median()\n",
    "for iter_range in range(df_no_outliers[feature].size):\n",
    "    if df_no_outliers.iloc[iter_range]['quality_label']!=\"high\":\n",
    "        if( (df_no_outliers.iloc[iter_range][feature]<=lower) or \\\n",
    "            (df_no_outliers.iloc[iter_range][feature]>=upper)):\n",
    "            df_no_outliers.iloc[iter_range,df_no_outliers.columns.get_loc(feature)] =median\n",
    "\n",
    "\n",
    "# Plot Feature \n",
    "sns.boxplot(x=df_no_outliers['quality_label'],y=df_no_outliers[feature])\n",
    "plt.title('After Outlier Removal')\n",
    "plt.show() \n",
    "# Check Count \n",
    "print('After Outlier Removal')\n",
    "print(df_no_outliers[df_no_outliers['quality_label']=='medium']['alcohol'].describe().loc['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Structuring # \n",
    "wines = pd.concat([red_wine, white_wine])\n",
    "wines = wines.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "wines = wines.drop(['quality'],axis=1)\n",
    "wines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We chose alcohol as a feature to remove the outliers, because alcohol has the highest correlation with quality, which is what we finally want to train a model to determine given the physiochemical wine properties as features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # --- Encoding Categorical Variables ---#\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "wines['wine_type'] = encoder.fit_transform(wines['wine_type'])\n",
    "wines['wine_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Analysis ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.style.use('default')\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(10,5)\n",
    "\n",
    "wines_corrmat = wines.corr()\n",
    "# Getting the Upper Triangle of the co-relation matrix\n",
    "matrix = np.triu(wines_corrmat)\n",
    "hm = sns.heatmap(wines_corrmat, annot = True, mask=matrix)\n",
    "hm.set(xlabel='wine composition ', ylabel='wine composition', title = \"Correlation matrix of wine data\\n\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import scipy.stats\n",
    "\n",
    "features = wines.select_dtypes(include=['float64']).columns\n",
    "\n",
    "for feature in features: \n",
    "\n",
    "    # F and p values\n",
    "    f_value, p_value = stats.f_oneway(wines[wines['quality_label'] == 'low'][feature],\n",
    "    wines[wines['quality_label'] == 'medium'][feature],\n",
    "    wines[wines['quality_label'] == 'high'][feature])\n",
    "    #print('ANOVA test for mean alcohol levels across wine samples with different quality ratings')\n",
    "    print(feature,' F Statistic:', f_value, '\\tp-value:', p_value)\n",
    "\n",
    "    # anova table as output\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.formula.api import ols\n",
    "\n",
    "    # Ordinary Least Squares (OLS) model\n",
    "    X = wines.iloc[:,:12]\n",
    "    y = wines['quality_label']\n",
    "    X = sm.add_constant(X)\n",
    "    model = ols(y,X).fit()\n",
    "    anova_table = sm.stats.anova_lm(model, typ=1)\n",
    "    anova_table\n",
    "\n",
    "#print('Critical Value: ', scipy.stats.f.ppf(q=0.05,dfn=2,dfd=6494))\n",
    "\n",
    "# ## Post-Hoc Test (Tukey's HSD) to see which labels differ #\n",
    "\n",
    "# from bioinfokit.analys import stat\n",
    "\n",
    "# res = stat()\n",
    "# res.tukey_hsd()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red and White Wine Classification using Machine Learning #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler # data normalisation with sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features & Target\n",
    "X = wines.select_dtypes(include=['float64'])\n",
    "y = wines['wine_type'] # --> what you're trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Split --- #\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)\n",
    "\n",
    "# --- Feature Scaling ---- # \n",
    "# fit scaler on training data\n",
    "norm = MinMaxScaler().fit(X_train)\n",
    "\n",
    "# transform training data\n",
    "X_train_norm = norm.transform(X_train)\n",
    "\n",
    "# transform testing data\n",
    "X_test_norm = norm.transform(X_test)\n",
    "\n",
    "X_train = X_train_norm\n",
    "X_test = X_test_norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing different models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# prepare configuration for cross validation test harness\n",
    "seed = 7\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model in models:\n",
    "\n",
    "\tkfold = model_selection.KFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "\tcv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n",
    "\n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison using cross validation results')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "  \n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#### Evaluation metrics ####\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "# Accuracy \n",
    "print('Accuracy Score: ', accuracy_score(y_test,y_pred))\n",
    "\n",
    "# Balanced Accuracy\n",
    "print('Balanced Accuracy Score: ', balanced_accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Classification Report \n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Kappa score \n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print(\"Cohen-Kappa score:\", kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18280ca97489113fafb1e8bde595a438efbff7c547ca8a138dcc023d9cb2edd5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
